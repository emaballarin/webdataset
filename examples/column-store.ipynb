{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using WebDataset as a Column Store\n",
    "\n",
    "Sometimes it is desirable to break up a dataset not just by rows but also by columns.\n",
    "This is quite easy in WebDataset, although there is no explicit API for it (one will likely be added).\n",
    "\n",
    "The idea is to just use the `__url__` field in a sample to load additional columns as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T05:38:36.126732Z",
     "iopub.status.busy": "2023-12-14T05:38:36.126472Z",
     "iopub.status.idle": "2023-12-14T05:38:36.138014Z",
     "shell.execute_reply": "2023-12-14T05:38:36.137312Z"
    }
   },
   "outputs": [],
   "source": [
    "# We usually abbreviate webdataset as wds\n",
    "import webdataset as wds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "bucket = \"https://storage.googleapis.com/webdataset/fake-imagenet\"\n",
    "training_urls = bucket + \"/imagenet-train-{000000..001281}.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-14T05:38:36.374043Z",
     "iopub.status.busy": "2023-12-14T05:38:36.372928Z",
     "iopub.status.idle": "2023-12-14T05:38:36.396581Z",
     "shell.execute_reply": "2023-12-14T05:38:36.395381Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the datasets with shard and sample shuffling and decoding.\n",
    "trainset = wds.WebDataset(training_urls, resampled=True, shardshuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function computes the URL for an additional column from a base URL. This is\n",
    "then used by the `add_column` function to add data from that additional URL to the\n",
    "data already loaded from the base URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_column_url(url):\n",
    "    # In this function, given the main URL for a shard, find the corresponding\n",
    "    # extra column URL.\n",
    "\n",
    "    # For the demo, we just return the same URL, which means that we simply\n",
    "    # add the same values to the samples twice.\n",
    "    return url # .replace(\"-train\", \"-train-more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column(src, find_column_url=find_column_url):\n",
    "    \"\"\"Given an iterator over a dataset, add an extra column from a separate dataset.\"\"\"\n",
    "    last_url = None\n",
    "    column_src = None\n",
    "    for sample in src:\n",
    "        # We use the __url__ field to keep track of which shard we are working on.\n",
    "        # We then open the corresponding URL for the extra column data if necessary.\n",
    "        if last_url != sample[\"__url__\"]:\n",
    "            column_url = find_column_url(sample[\"__url__\"])\n",
    "            print(\"*** opening column_url\", column_url)\n",
    "            column_src = iter(wds.WebDataset(column_url, shardshuffle=False))\n",
    "            last_url = sample[\"__url__\"]\n",
    "        # Read the next sample from the extra column data.\n",
    "        extra = next(column_src)\n",
    "        # Check that the keys match.\n",
    "        assert extra[\"__key__\"] == sample[\"__key__\"]\n",
    "        # Update the sample with the extra data.\n",
    "        for k, v in extra.items():\n",
    "            if k[0] != \"_\":\n",
    "                sample[k] = v\n",
    "        yield sample\n",
    "\n",
    "trainset = trainset.compose(add_column)\n",
    "\n",
    "# NB: any shuffling, decoding, etc. needs to happen after the `add_column` call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see all of it in action. Actually, nothing particularly interesting happens here\n",
    "because we are just loading the same data for the base URL and the additional column.\n",
    "Really, the only feedback you get from this code is the message about opening the column_url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** opening column_url https://storage.googleapis.com/webdataset/fake-imagenet/imagenet-train-001010.tar\n",
      "__key__ '001010-000002'\n",
      "__url__ 'https://storage.googleapis.com/webdataset/fake-imagenet/ima\n",
      "cls b'9'\n",
      "jpg b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x\n",
      "txt b'a high quality color photograph of a frog'\n"
     ]
    }
   ],
   "source": [
    "for k, v in next(iter(trainset)).items():\n",
    "    print(k, repr(v)[:60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some comments:\n",
    "\n",
    "- The code above assumes an exact correspondence between the samples in the different columnn shards; this is really what you ought to aim for. But you can add code to skip data.\n",
    "- For small amounts of data (like class labels), you probably just want to store the data in a dbm-style database and use `.associate(data)`.\n",
    "- You could also use `wids` to retrieve additional samples in `add_column`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to do the same thing in `wids`, the code becomes even simpler:\n",
    "\n",
    "```Python\n",
    "class CombinedDataset:\n",
    "    def __init__(self, ds1, ds2):\n",
    "        self.ds1 = wids.ShardListDataset(ds1)\n",
    "        self.ds2 = wids.ShardListDataset(ds2)\n",
    "        assert len(self.ds1) == len(self.ds2)\n",
    "    def getitem(self, index):\n",
    "        return self.ds1[index].update(self.ds2[index])\n",
    "    def __len__(self):\n",
    "        return len(self.ds1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
