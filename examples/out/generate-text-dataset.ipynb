{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fdffc0d",
   "metadata": {
    "papermill": {
     "duration": 0.005286,
     "end_time": "2023-12-18T07:53:07.636392",
     "exception": false,
     "start_time": "2023-12-18T07:53:07.631106",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Generation\n",
    "\n",
    "This is a simple example of dataset generation using WebDataset `TarWriter`. Shard are uploaded to a server or to the cloud as they are generated.\n",
    "\n",
    "Parallel dataset generation with Ray is illustrated at the very end.\n",
    "\n",
    "This particular notebook generates short text samples using GPT-2. These can be used to generate OCR training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac80742b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T07:53:07.647236Z",
     "iopub.status.busy": "2023-12-18T07:53:07.646940Z",
     "iopub.status.idle": "2023-12-18T07:53:07.660658Z",
     "shell.execute_reply": "2023-12-18T07:53:07.659411Z"
    },
    "id": "61u4BASSNq6y",
    "papermill": {
     "duration": 0.022009,
     "end_time": "2023-12-18T07:53:07.663305",
     "exception": false,
     "start_time": "2023-12-18T07:53:07.641296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# package installs for colab\n",
    "\n",
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    !pip install --quiet webdataset\n",
    "    !pip install --quiet adapter-transformers\n",
    "    !pip install --quiet sentencepiece\n",
    "    !pip install --quiet datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a58959bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243,
     "referenced_widgets": [
      "5011003a97364ffbaf0ba5c49f40a856",
      "8a24d38e49e845e68f949fd7e950c547",
      "11d4db32b02f45b89455ae3c7c1b48e7",
      "f68aa4ffbe37471ab728a5bfdd96a162",
      "a53f2b82f0c5473f887c87415441c851",
      "f6a5e728da38475fbbda774a43f529fb",
      "5e417069faed471392193db141b2851b",
      "4cb67b0c60bb4b1ba719897a2baac500",
      "1dc2b10916f14ee58c92be8159cf2e1e",
      "dcf507a023d24a29b56e871f7ddb4c3b",
      "c8a631d4c2bd4b2a91d54ee394c8fc71"
     ]
    },
    "execution": {
     "iopub.execute_input": "2023-12-18T07:53:07.675154Z",
     "iopub.status.busy": "2023-12-18T07:53:07.674655Z",
     "iopub.status.idle": "2023-12-18T07:53:09.387428Z",
     "shell.execute_reply": "2023-12-18T07:53:09.386626Z"
    },
    "id": "jrEQw7TXLqxC",
    "outputId": "8957bc2d-b768-4ad9-edba-d610f805b071",
    "papermill": {
     "duration": 1.722475,
     "end_time": "2023-12-18T07:53:09.390589",
     "exception": false,
     "start_time": "2023-12-18T07:53:07.668114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "import webdataset as wds\n",
    "import os\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from transformers import pipeline\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f71fc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T07:53:09.406108Z",
     "iopub.status.busy": "2023-12-18T07:53:09.405798Z",
     "iopub.status.idle": "2023-12-18T07:53:09.409394Z",
     "shell.execute_reply": "2023-12-18T07:53:09.408696Z"
    },
    "papermill": {
     "duration": 0.013787,
     "end_time": "2023-12-18T07:53:09.411910",
     "exception": false,
     "start_time": "2023-12-18T07:53:09.398123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "nsamples = 10\n",
    "ntokens = 100\n",
    "nshards = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdca9b8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T07:53:09.426372Z",
     "iopub.status.busy": "2023-12-18T07:53:09.426166Z",
     "iopub.status.idle": "2023-12-18T07:53:14.248603Z",
     "shell.execute_reply": "2023-12-18T07:53:14.248018Z"
    },
    "papermill": {
     "duration": 4.833082,
     "end_time": "2023-12-18T07:53:14.251680",
     "exception": false,
     "start_time": "2023-12-18T07:53:09.418598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tmb/proj/webdataset/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1190: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "It is the fifth consecutive week that the U.S. Postal Service\n",
      "has suspended service to nearly 3,600 customers. According to\n",
      "the Postal Service's website, about 3,700 service disruptions\n",
      "are caused by a change in service or a drop-off in service\n",
      "within five business days. When this happens, the post office\n",
      "will post the same letter and e-mail address as it received the\n",
      "previous day.  The latest incident of such a large public\n",
      "service disruption is being described as the most\n"
     ]
    }
   ],
   "source": [
    "# text generation with Huggingface and GPT2\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", padding_side=\"left\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "def generate(n, prompt=\"\"):\n",
    "    \"\"\"Generate n words of text, starting with prompt.\"\"\"\n",
    "    global tokenizer, model, generator\n",
    "    output = generator(\n",
    "        prompt,\n",
    "        max_length=n + len(tokenizer.encode(prompt)),\n",
    "        do_sample=True,\n",
    "        temperature=0.99,\n",
    "        top_k=50,\n",
    "        top_p=0.99,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )[0]\n",
    "    return output[\"generated_text\"]\n",
    "\n",
    "\n",
    "text = generate(100).strip()\n",
    "print()\n",
    "print(textwrap.fill(text, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47a6230c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T07:53:14.264945Z",
     "iopub.status.busy": "2023-12-18T07:53:14.264740Z",
     "iopub.status.idle": "2023-12-18T07:53:42.788926Z",
     "shell.execute_reply": "2023-12-18T07:53:42.787070Z"
    },
    "id": "ElUfC0IbaPnR",
    "papermill": {
     "duration": 28.532007,
     "end_time": "2023-12-18T07:53:42.792693",
     "exception": false,
     "start_time": "2023-12-18T07:53:14.260686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GOPEN temp.tar {}\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0 : 'Pricing\\n\\nWe are interested in'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 tmb tmb 30720 Dec 17 23:53 temp.tar\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de0e698c84ad4662812b74331bbd6ac4.txt.gz\r\n",
      "eb933c45c4f048fc90666697555ae577.txt.gz\r\n",
      "4c918b92e44644eb8cc35b01af45793a.txt.gz\r\n",
      "ca84a94cdc774e22a79ad393c68e7be2.txt.gz\r\n",
      "b078a0f605ab48d880617eecae910517.txt.gz\r\n"
     ]
    }
   ],
   "source": [
    "# function generating an entire shard using TarWriter\n",
    "\n",
    "\n",
    "def generate_shard(oname, nsamples=10000, ntokens=500, prefix=\"\"):\n",
    "    \"\"\"Generate a shard of samples with text.\n",
    "\n",
    "    Each sample has a \"__key__\" field and a \"txt.gz\" field.\n",
    "    That is, the individual text files are compressed automatically on write.\n",
    "    They will be automatically decompressed when read.\n",
    "    \"\"\"\n",
    "    with wds.TarWriter(oname) as output:\n",
    "        for i in range(nsamples):\n",
    "            text = generate(100).strip()\n",
    "            key = uuid.uuid4().hex\n",
    "            text = generate(ntokens)\n",
    "            sample = {\"__key__\": key, \"txt.gz\": text}\n",
    "            output.write(sample)\n",
    "            if i % 10 == 0:\n",
    "                print(f\"{i:6d} {prefix}:\", repr(text)[:60])\n",
    "\n",
    "\n",
    "generate_shard(\"temp.tar\", nsamples=10, ntokens=10)\n",
    "!ls -l temp.tar\n",
    "!tar tf temp.tar | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af3e389f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T07:53:42.818633Z",
     "iopub.status.busy": "2023-12-18T07:53:42.818054Z",
     "iopub.status.idle": "2023-12-18T07:53:42.827564Z",
     "shell.execute_reply": "2023-12-18T07:53:42.825950Z"
    },
    "id": "u6I69B4FbPbk",
    "papermill": {
     "duration": 0.026511,
     "end_time": "2023-12-18T07:53:42.831050",
     "exception": false,
     "start_time": "2023-12-18T07:53:42.804539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We need a couple of simple functions to upload to the cloud.\n",
    "\n",
    "\n",
    "def cloud_exists(oname):\n",
    "    \"\"\"Check whether a file exists in the cloud.\"\"\"\n",
    "    # return os.system(f\"gsutil stat gs://mybucket/500tokens/{oname}\") == 0\n",
    "    return True\n",
    "\n",
    "\n",
    "def cloud_upload(oname):\n",
    "    \"\"\"Upload a file to the cloud.\"\"\"\n",
    "    # assert os.system(f\"gsutil cp {oname} gs://mybucket/500tokens/{oname}\") == 0\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "067ad21a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T07:53:42.855606Z",
     "iopub.status.busy": "2023-12-18T07:53:42.855072Z",
     "iopub.status.idle": "2023-12-18T07:53:42.864883Z",
     "shell.execute_reply": "2023-12-18T07:53:42.863152Z"
    },
    "papermill": {
     "duration": 0.026054,
     "end_time": "2023-12-18T07:53:42.868224",
     "exception": false,
     "start_time": "2023-12-18T07:53:42.842170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can now generate a shard and upload it to the cloud.\n",
    "# We skip the generation if the file already exists in the cloud.\n",
    "\n",
    "\n",
    "def generate_and_upload(i):\n",
    "    \"\"\"Generate a shard and upload it to the cloud.\"\"\"\n",
    "    oname = f\"text-{i:06d}.tar\"\n",
    "    if cloud_exists(oname):\n",
    "        print(f\"{oname} already exists, skipping\")\n",
    "        return False\n",
    "    generate_shard(oname, nsamples=nsamples, ntokens=ntokens, prefix=f\"{i:6d} {oname}\")\n",
    "    cloud_upload(oname)\n",
    "    os.remove(oname)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36aeaee8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T07:53:42.887982Z",
     "iopub.status.busy": "2023-12-18T07:53:42.887439Z",
     "iopub.status.idle": "2023-12-18T07:53:42.895449Z",
     "shell.execute_reply": "2023-12-18T07:53:42.893914Z"
    },
    "papermill": {
     "duration": 0.0193,
     "end_time": "2023-12-18T07:53:42.897972",
     "exception": false,
     "start_time": "2023-12-18T07:53:42.878672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-000000.tar already exists, skipping\n",
      "text-000001.tar already exists, skipping\n",
      "text-000002.tar already exists, skipping\n"
     ]
    }
   ],
   "source": [
    "# For sequential generation, use this\n",
    "\n",
    "for i in range(nshards):\n",
    "    generate_and_upload(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4668c0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-18T07:53:42.914772Z",
     "iopub.status.busy": "2023-12-18T07:53:42.914227Z",
     "iopub.status.idle": "2023-12-18T07:53:42.957843Z",
     "shell.execute_reply": "2023-12-18T07:53:42.956330Z"
    },
    "id": "rjtefVDI-DfZ",
    "papermill": {
     "duration": 0.055393,
     "end_time": "2023-12-18T07:53:42.960894",
     "exception": false,
     "start_time": "2023-12-18T07:53:42.905501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%script true\n",
    "# For parallel generation, use this\n",
    "\n",
    "import ray\n",
    "\n",
    "@ray.remote(num_cpus=1, num_gpus=1)\n",
    "def ray_generate_and_upload(i):\n",
    "    \"\"\"A Ray remote function that generates a shard and uploads it to the cloud.\"\"\"\n",
    "    return generate_and_upload(i)\n",
    "\n",
    "def generate_shards(nshards=10):\n",
    "    \"\"\"Generate a number of shards and upload them to the cloud.\n",
    "    \n",
    "    Runs in parallel on a Ray cluster.\n",
    "    \"\"\"\n",
    "    ray.init(address='auto')  # Connect to the Ray cluster\n",
    "    tasks = [ray_generate_and_upload.remote(i) for i in range(nshards)]\n",
    "    ray.shutdown()\n",
    "    return shard_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef935e8",
   "metadata": {
    "papermill": {
     "duration": 0.008413,
     "end_time": "2023-12-18T07:53:42.977921",
     "exception": false,
     "start_time": "2023-12-18T07:53:42.969508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 36.964241,
   "end_time": "2023-12-18T07:53:43.708240",
   "environment_variables": {},
   "exception": null,
   "input_path": "generate-text-dataset.ipynb",
   "output_path": "out/_generate-text-dataset.ipynb",
   "parameters": {},
   "start_time": "2023-12-18T07:53:06.743999",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "11d4db32b02f45b89455ae3c7c1b48e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cb67b0c60bb4b1ba719897a2baac500",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1dc2b10916f14ee58c92be8159cf2e1e",
      "value": 0
     }
    },
    "1dc2b10916f14ee58c92be8159cf2e1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4cb67b0c60bb4b1ba719897a2baac500": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "5011003a97364ffbaf0ba5c49f40a856": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8a24d38e49e845e68f949fd7e950c547",
       "IPY_MODEL_11d4db32b02f45b89455ae3c7c1b48e7",
       "IPY_MODEL_f68aa4ffbe37471ab728a5bfdd96a162"
      ],
      "layout": "IPY_MODEL_a53f2b82f0c5473f887c87415441c851"
     }
    },
    "5e417069faed471392193db141b2851b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a24d38e49e845e68f949fd7e950c547": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6a5e728da38475fbbda774a43f529fb",
      "placeholder": "​",
      "style": "IPY_MODEL_5e417069faed471392193db141b2851b",
      "value": ""
     }
    },
    "a53f2b82f0c5473f887c87415441c851": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8a631d4c2bd4b2a91d54ee394c8fc71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dcf507a023d24a29b56e871f7ddb4c3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f68aa4ffbe37471ab728a5bfdd96a162": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcf507a023d24a29b56e871f7ddb4c3b",
      "placeholder": "​",
      "style": "IPY_MODEL_c8a631d4c2bd4b2a91d54ee394c8fc71",
      "value": " 0/0 [00:00&lt;?, ?it/s]"
     }
    },
    "f6a5e728da38475fbbda774a43f529fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}